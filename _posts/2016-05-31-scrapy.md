---
layout:     post
title:      "scrapy 学习笔记"
subtitle:   ""
date:       2016-5-31 12:00:00
author:     "boredream"
catalog: false
header-style: text
tags:
- scrapy
- python

---

python学习过程略过，网上找教程，这里记录下scrapy学习的经验记录


Item 抓取的每条信息对象，常用的可以定义title，link，desc等


编写步骤
1. 打开需要爬取网站，打开审查元素查看需要爬取数据的标签
2. 在命令行输入 scrapy startproject douban 创建scrapy爬虫项目，douban为项目名
3. PyCharm 导入项目，
4. 根据需要爬去的内容编写Item类
```python
import scrapy

class DmozItem(scrapy.Item):
    title = scrapy.Field()
    link = scrapy.Field()
    desc = scrapy.Field()
```
5. spider文件夹下新建自定义Spider类，并继承scrapy的BaseSpider类
     parse中编写对html的解析代码，利用[xpath规则](http://www.w3school.com.cn/xpath/index.asp)
     1）for循环每一个数据item标签
     2）xpath解析每一个数据item中需要的数据，赋值给item变量
     3）yield item
```python
from scrapy.spider import BaseSpider
from tutorial.items import DmozItem

class DmozSpider(BaseSpider):
    name = "dmoz"
    allowed_domains = ["dmoz.org"]
    start_urls = [
        "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/",
        "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"
    ]

    def parse(self, response):

        for sel in response.xpath('//ul/li'):
            item = DmozItem()
            item['title'] = sel.xpath('a/text()').extract()
            item['link'] = sel.xpath('a/@href').extract()
            item['desc'] = sel.xpath('text()').extract()
            yield item
```
5. 命令行输入 scrapy crawl dmoz -o items.json  运行爬虫将数据保存在items.json中
或者配置保存json的pipelines，然后在setting中设置


多页爬取
利用yield Request(url='blablabla’, call=self.parse)递归自己，可以自行加入条件判断结束，实现多页爬取


pipeline
用于处理item，比如验证，保存等
```python
import json
import codecs

class DribbblePipeline(object):
    def __init__(self):
        self.file = codecs.open('items.json', 'wb', encoding='utf-8')

    def process_item(self, item, spider):
        line = json.dumps(dict(item)) + '\n'
        # print line
        self.file.write(line.decode("unicode_escape"))
        return item
```
然后在setting.py中添加
```python
ITEM_PIPELINES = {
   'tutorial.pipelines.DribbblePipeline': 300,
}
```

指令运行完后，在items.json中查看数据，也可以处理成其他自己需要的数据格式如保存到数据库or保存表格文件等。
